mparsian@Mahmouds-MacBook:~/spark-1.2.1/bin# cat data.txt
fox jumped high
fox is crazy
crazy fox is here
fox is red

Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.2.1
      /_/

Using Python version 2.6.9 (unknown, Sep  9 2014 15:05:12)
SparkContext available as sc.
>>> sc
<pyspark.context.SparkContext object at 0x1017ec210>
>>> lines = sc.textFile("data.txt");
15/03/04 22:31:50 INFO MemoryStore: ensureFreeSpace(182921) called with curMem=0, maxMem=278302556
15/03/04 22:31:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 178.6 KB, free 265.2 MB)
15/03/04 22:31:50 INFO MemoryStore: ensureFreeSpace(25432) called with curMem=182921, maxMem=278302556
15/03/04 22:31:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.8 KB, free 265.2 MB)
15/03/04 22:31:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:63371 (size: 24.8 KB, free: 265.4 MB)
15/03/04 22:31:50 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/03/04 22:31:50 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
>>> lines.collect()
15/03/04 22:32:00 INFO FileInputFormat: Total input paths to process : 1
15/03/04 22:32:00 INFO SparkContext: Starting job: collect at <stdin>:1
15/03/04 22:32:00 INFO DAGScheduler: Got job 0 (collect at <stdin>:1) with 2 output partitions (allowLocal=false)
15/03/04 22:32:00 INFO DAGScheduler: Final stage: Stage 0(collect at <stdin>:1)
15/03/04 22:32:00 INFO DAGScheduler: Parents of final stage: List()
15/03/04 22:32:00 INFO DAGScheduler: Missing parents: List()
15/03/04 22:32:00 INFO DAGScheduler: Submitting Stage 0 (data.txt MappedRDD[1] at textFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/03/04 22:32:00 INFO MemoryStore: ensureFreeSpace(2528) called with curMem=208353, maxMem=278302556
15/03/04 22:32:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/03/04 22:32:00 INFO MemoryStore: ensureFreeSpace(1871) called with curMem=210881, maxMem=278302556
15/03/04 22:32:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1871.0 B, free 265.2 MB)
15/03/04 22:32:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:63371 (size: 1871.0 B, free: 265.4 MB)
15/03/04 22:32:00 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/03/04 22:32:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:838
15/03/04 22:32:00 INFO DAGScheduler: Submitting 2 missing tasks from Stage 0 (data.txt MappedRDD[1] at textFile at NativeMethodAccessorImpl.java:-2)
15/03/04 22:32:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/03/04 22:32:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:32:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:32:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/03/04 22:32:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/03/04 22:32:00 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:0+29
15/03/04 22:32:00 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:29+29
15/03/04 22:32:00 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/03/04 22:32:00 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/03/04 22:32:00 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/03/04 22:32:00 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/03/04 22:32:00 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/03/04 22:32:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1772 bytes result sent to driver
15/03/04 22:32:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1732 bytes result sent to driver
15/03/04 22:32:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 66 ms on localhost (1/2)
15/03/04 22:32:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 61 ms on localhost (2/2)
15/03/04 22:32:01 INFO DAGScheduler: Stage 0 (collect at <stdin>:1) finished in 0.076 s
15/03/04 22:32:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
15/03/04 22:32:01 INFO DAGScheduler: Job 0 finished: collect at <stdin>:1, took 0.117521 s
[u'fox jumped high', u'fox is crazy', u'crazy fox is here', u'fox is red']
>>> words = lines.map(lambda x: x.split())
>>> words.collect()
15/03/04 22:33:21 INFO SparkContext: Starting job: collect at <stdin>:1
15/03/04 22:33:21 INFO DAGScheduler: Got job 1 (collect at <stdin>:1) with 2 output partitions (allowLocal=false)
15/03/04 22:33:21 INFO DAGScheduler: Final stage: Stage 1(collect at <stdin>:1)
15/03/04 22:33:21 INFO DAGScheduler: Parents of final stage: List()
15/03/04 22:33:21 INFO DAGScheduler: Missing parents: List()
15/03/04 22:33:21 INFO DAGScheduler: Submitting Stage 1 (PythonRDD[2] at collect at <stdin>:1), which has no missing parents
15/03/04 22:33:21 INFO MemoryStore: ensureFreeSpace(4456) called with curMem=212752, maxMem=278302556
15/03/04 22:33:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.4 KB, free 265.2 MB)
15/03/04 22:33:21 INFO MemoryStore: ensureFreeSpace(3316) called with curMem=217208, maxMem=278302556
15/03/04 22:33:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.2 KB, free 265.2 MB)
15/03/04 22:33:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:63371 (size: 3.2 KB, free: 265.4 MB)
15/03/04 22:33:21 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/03/04 22:33:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:838
15/03/04 22:33:21 INFO DAGScheduler: Submitting 2 missing tasks from Stage 1 (PythonRDD[2] at collect at <stdin>:1)
15/03/04 22:33:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/03/04 22:33:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:33:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:33:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/03/04 22:33:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/03/04 22:33:21 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:29+29
15/03/04 22:33:21 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:0+29
15/03/04 22:33:21 INFO PythonRDD: Times: total = 154, boot = 150, init = 4, finish = 0
15/03/04 22:33:21 INFO PythonRDD: Times: total = 154, boot = 147, init = 7, finish = 0
15/03/04 22:33:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1829 bytes result sent to driver
15/03/04 22:33:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1935 bytes result sent to driver
15/03/04 22:33:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 165 ms on localhost (1/2)
15/03/04 22:33:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 165 ms on localhost (2/2)
15/03/04 22:33:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
15/03/04 22:33:21 INFO DAGScheduler: Stage 1 (collect at <stdin>:1) finished in 0.167 s
15/03/04 22:33:21 INFO DAGScheduler: Job 1 finished: collect at <stdin>:1, took 0.178748 s
[[u'fox', u'jumped', u'high'], [u'fox', u'is', u'crazy'], [u'crazy', u'fox', u'is', u'here'], [u'fox', u'is', u'red']]
>>> bigrams = words.flatMap(lambda x : [ (x[i],x[i+1]) for i in range(0,len(x)-1)])
>>> bigrams.collect()
15/03/04 22:35:13 INFO SparkContext: Starting job: collect at <stdin>:1
15/03/04 22:35:13 INFO DAGScheduler: Got job 2 (collect at <stdin>:1) with 2 output partitions (allowLocal=false)
15/03/04 22:35:13 INFO DAGScheduler: Final stage: Stage 2(collect at <stdin>:1)
15/03/04 22:35:13 INFO DAGScheduler: Parents of final stage: List()
15/03/04 22:35:13 INFO DAGScheduler: Missing parents: List()
15/03/04 22:35:13 INFO DAGScheduler: Submitting Stage 2 (PythonRDD[3] at collect at <stdin>:1), which has no missing parents
15/03/04 22:35:13 INFO MemoryStore: ensureFreeSpace(5056) called with curMem=220524, maxMem=278302556
15/03/04 22:35:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.9 KB, free 265.2 MB)
15/03/04 22:35:13 INFO MemoryStore: ensureFreeSpace(3823) called with curMem=225580, maxMem=278302556
15/03/04 22:35:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/03/04 22:35:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:63371 (size: 3.7 KB, free: 265.4 MB)
15/03/04 22:35:13 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/03/04 22:35:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:838
15/03/04 22:35:13 INFO DAGScheduler: Submitting 2 missing tasks from Stage 2 (PythonRDD[3] at collect at <stdin>:1)
15/03/04 22:35:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/03/04 22:35:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:35:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:35:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/03/04 22:35:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/03/04 22:35:13 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:0+29
15/03/04 22:35:13 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:29+29
15/03/04 22:35:13 INFO PythonRDD: Times: total = 6, boot = 2, init = 3, finish = 1
15/03/04 22:35:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 1969 bytes result sent to driver
15/03/04 22:35:13 INFO PythonRDD: Times: total = 7, boot = 4, init = 2, finish = 1
15/03/04 22:35:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1850 bytes result sent to driver
15/03/04 22:35:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 14 ms on localhost (1/2)
15/03/04 22:35:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 15 ms on localhost (2/2)
15/03/04 22:35:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
15/03/04 22:35:13 INFO DAGScheduler: Stage 2 (collect at <stdin>:1) finished in 0.017 s
15/03/04 22:35:13 INFO DAGScheduler: Job 2 finished: collect at <stdin>:1, took 0.027069 s
[(u'fox', u'jumped'), (u'jumped', u'high'), (u'fox', u'is'), (u'is', u'crazy'), (u'crazy', u'fox'), (u'fox', u'is'), (u'is', u'here'), (u'fox', u'is'), (u'is', u'red')]
>>> ones = bigrams.map(lambda x : (x,1))
>>> ones.collect()
15/03/04 22:36:53 INFO SparkContext: Starting job: collect at <stdin>:1
15/03/04 22:36:53 INFO DAGScheduler: Got job 3 (collect at <stdin>:1) with 2 output partitions (allowLocal=false)
15/03/04 22:36:53 INFO DAGScheduler: Final stage: Stage 3(collect at <stdin>:1)
15/03/04 22:36:53 INFO DAGScheduler: Parents of final stage: List()
15/03/04 22:36:53 INFO DAGScheduler: Missing parents: List()
15/03/04 22:36:53 INFO DAGScheduler: Submitting Stage 3 (PythonRDD[4] at collect at <stdin>:1), which has no missing parents
15/03/04 22:36:53 INFO MemoryStore: ensureFreeSpace(5232) called with curMem=229403, maxMem=278302556
15/03/04 22:36:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.1 KB, free 265.2 MB)
15/03/04 22:36:53 INFO MemoryStore: ensureFreeSpace(4006) called with curMem=234635, maxMem=278302556
15/03/04 22:36:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/03/04 22:36:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:63371 (size: 3.9 KB, free: 265.4 MB)
15/03/04 22:36:53 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
15/03/04 22:36:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:838
15/03/04 22:36:53 INFO DAGScheduler: Submitting 2 missing tasks from Stage 3 (PythonRDD[4] at collect at <stdin>:1)
15/03/04 22:36:53 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
15/03/04 22:36:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:36:53 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:36:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
15/03/04 22:36:53 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
15/03/04 22:36:53 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:0+29
15/03/04 22:36:53 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:29+29
15/03/04 22:36:53 INFO PythonRDD: Times: total = 6, boot = 3, init = 3, finish = 0
15/03/04 22:36:53 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2003 bytes result sent to driver
15/03/04 22:36:53 INFO PythonRDD: Times: total = 7, boot = 5, init = 2, finish = 0
15/03/04 22:36:53 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1858 bytes result sent to driver
15/03/04 22:36:53 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 14 ms on localhost (1/2)
15/03/04 22:36:53 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 14 ms on localhost (2/2)
15/03/04 22:36:53 INFO DAGScheduler: Stage 3 (collect at <stdin>:1) finished in 0.016 s
15/03/04 22:36:53 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
15/03/04 22:36:53 INFO DAGScheduler: Job 3 finished: collect at <stdin>:1, took 0.026507 s
[((u'fox', u'jumped'), 1), ((u'jumped', u'high'), 1), ((u'fox', u'is'), 1), ((u'is', u'crazy'), 1), ((u'crazy', u'fox'), 1), ((u'fox', u'is'), 1), ((u'is', u'here'), 1), ((u'fox', u'is'), 1), ((u'is', u'red'), 1)]
>>> frequency = ones.reduceByKey(lambda x, y: x+y)
>>> ones.collect();
15/03/04 22:37:50 INFO SparkContext: Starting job: collect at <stdin>:1
15/03/04 22:37:50 INFO DAGScheduler: Got job 4 (collect at <stdin>:1) with 2 output partitions (allowLocal=false)
15/03/04 22:37:50 INFO DAGScheduler: Final stage: Stage 4(collect at <stdin>:1)
15/03/04 22:37:50 INFO DAGScheduler: Parents of final stage: List()
15/03/04 22:37:50 INFO DAGScheduler: Missing parents: List()
15/03/04 22:37:50 INFO DAGScheduler: Submitting Stage 4 (PythonRDD[4] at collect at <stdin>:1), which has no missing parents
15/03/04 22:37:50 INFO MemoryStore: ensureFreeSpace(5232) called with curMem=238641, maxMem=278302556
15/03/04 22:37:50 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.1 KB, free 265.2 MB)
15/03/04 22:37:50 INFO MemoryStore: ensureFreeSpace(4006) called with curMem=243873, maxMem=278302556
15/03/04 22:37:50 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/03/04 22:37:50 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:63371 (size: 3.9 KB, free: 265.4 MB)
15/03/04 22:37:50 INFO BlockManagerMaster: Updated info of block broadcast_5_piece0
15/03/04 22:37:50 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:838
15/03/04 22:37:50 INFO DAGScheduler: Submitting 2 missing tasks from Stage 4 (PythonRDD[4] at collect at <stdin>:1)
15/03/04 22:37:50 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
15/03/04 22:37:50 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:37:50 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, localhost, PROCESS_LOCAL, 1309 bytes)
15/03/04 22:37:50 INFO Executor: Running task 0.0 in stage 4.0 (TID 8)
15/03/04 22:37:50 INFO Executor: Running task 1.0 in stage 4.0 (TID 9)
15/03/04 22:37:50 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:0+29
15/03/04 22:37:50 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:29+29
15/03/04 22:37:50 INFO PythonRDD: Times: total = 3, boot = -57103, init = 57106, finish = 0
15/03/04 22:37:50 INFO PythonRDD: Times: total = 3, boot = -57103, init = 57106, finish = 0
15/03/04 22:37:50 INFO Executor: Finished task 0.0 in stage 4.0 (TID 8). 2003 bytes result sent to driver
15/03/04 22:37:50 INFO Executor: Finished task 1.0 in stage 4.0 (TID 9). 1858 bytes result sent to driver
15/03/04 22:37:50 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 11 ms on localhost (1/2)
15/03/04 22:37:50 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 11 ms on localhost (2/2)
15/03/04 22:37:50 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
15/03/04 22:37:50 INFO DAGScheduler: Stage 4 (collect at <stdin>:1) finished in 0.013 s
15/03/04 22:37:50 INFO DAGScheduler: Job 4 finished: collect at <stdin>:1, took 0.023726 s
[((u'fox', u'jumped'), 1), ((u'jumped', u'high'), 1), ((u'fox', u'is'), 1), ((u'is', u'crazy'), 1), ((u'crazy', u'fox'), 1), ((u'fox', u'is'), 1), ((u'is', u'here'), 1), ((u'fox', u'is'), 1), ((u'is', u'red'), 1)]
>>> frequency.collect();
15/03/04 22:38:13 INFO SparkContext: Starting job: collect at <stdin>:1
15/03/04 22:38:13 INFO DAGScheduler: Registering RDD 6 (reduceByKey at <stdin>:1)
15/03/04 22:38:13 INFO DAGScheduler: Got job 5 (collect at <stdin>:1) with 2 output partitions (allowLocal=false)
15/03/04 22:38:13 INFO DAGScheduler: Final stage: Stage 6(collect at <stdin>:1)
15/03/04 22:38:13 INFO DAGScheduler: Parents of final stage: List(Stage 5)
15/03/04 22:38:13 INFO DAGScheduler: Missing parents: List(Stage 5)
15/03/04 22:38:13 INFO DAGScheduler: Submitting Stage 5 (PairwiseRDD[6] at reduceByKey at <stdin>:1), which has no missing parents
15/03/04 22:38:13 INFO MemoryStore: ensureFreeSpace(8208) called with curMem=247879, maxMem=278302556
15/03/04 22:38:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.0 KB, free 265.2 MB)
15/03/04 22:38:13 INFO MemoryStore: ensureFreeSpace(6251) called with curMem=256087, maxMem=278302556
15/03/04 22:38:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.1 KB, free 265.2 MB)
15/03/04 22:38:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:63371 (size: 6.1 KB, free: 265.4 MB)
15/03/04 22:38:13 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
15/03/04 22:38:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:838
15/03/04 22:38:13 INFO DAGScheduler: Submitting 2 missing tasks from Stage 5 (PairwiseRDD[6] at reduceByKey at <stdin>:1)
15/03/04 22:38:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
15/03/04 22:38:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, localhost, PROCESS_LOCAL, 1298 bytes)
15/03/04 22:38:13 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, localhost, PROCESS_LOCAL, 1298 bytes)
15/03/04 22:38:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 10)
15/03/04 22:38:13 INFO Executor: Running task 1.0 in stage 5.0 (TID 11)
15/03/04 22:38:13 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:29+29
15/03/04 22:38:13 INFO HadoopRDD: Input split: file:/Users/mparsian/spark-1.2.1/bin/data.txt:0+29
15/03/04 22:38:13 INFO PythonRDD: Times: total = 3, boot = -22795, init = 22798, finish = 0
15/03/04 22:38:13 INFO PythonRDD: Times: total = 3, boot = -22795, init = 22798, finish = 0
15/03/04 22:38:13 INFO Executor: Finished task 1.0 in stage 5.0 (TID 11). 1958 bytes result sent to driver
15/03/04 22:38:13 INFO Executor: Finished task 0.0 in stage 5.0 (TID 10). 1958 bytes result sent to driver
15/03/04 22:38:13 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 46 ms on localhost (1/2)
15/03/04 22:38:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 47 ms on localhost (2/2)
15/03/04 22:38:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
15/03/04 22:38:13 INFO DAGScheduler: Stage 5 (reduceByKey at <stdin>:1) finished in 0.050 s
15/03/04 22:38:13 INFO DAGScheduler: looking for newly runnable stages
15/03/04 22:38:13 INFO DAGScheduler: running: Set()
15/03/04 22:38:13 INFO DAGScheduler: waiting: Set(Stage 6)
15/03/04 22:38:13 INFO DAGScheduler: failed: Set()
15/03/04 22:38:13 INFO DAGScheduler: Missing parents for Stage 6: List()
15/03/04 22:38:13 INFO DAGScheduler: Submitting Stage 6 (PythonRDD[9] at collect at <stdin>:1), which is now runnable
15/03/04 22:38:13 INFO MemoryStore: ensureFreeSpace(4696) called with curMem=262338, maxMem=278302556
15/03/04 22:38:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.6 KB, free 265.2 MB)
15/03/04 22:38:13 INFO MemoryStore: ensureFreeSpace(3402) called with curMem=267034, maxMem=278302556
15/03/04 22:38:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.3 KB, free 265.2 MB)
15/03/04 22:38:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:63371 (size: 3.3 KB, free: 265.4 MB)
15/03/04 22:38:13 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
15/03/04 22:38:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:838
15/03/04 22:38:13 INFO DAGScheduler: Submitting 2 missing tasks from Stage 6 (PythonRDD[9] at collect at <stdin>:1)
15/03/04 22:38:13 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
15/03/04 22:38:13 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, PROCESS_LOCAL, 1056 bytes)
15/03/04 22:38:13 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, PROCESS_LOCAL, 1056 bytes)
15/03/04 22:38:13 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
15/03/04 22:38:13 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
15/03/04 22:38:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/03/04 22:38:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/03/04 22:38:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/03/04 22:38:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/03/04 22:38:13 INFO PythonRDD: Times: total = 28, boot = -52, init = 80, finish = 0
15/03/04 22:38:13 INFO PythonRDD: Times: total = 28, boot = -52, init = 80, finish = 0
15/03/04 22:38:13 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 1055 bytes result sent to driver
15/03/04 22:38:13 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 974 bytes result sent to driver
15/03/04 22:38:13 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 36 ms on localhost (1/2)
15/03/04 22:38:13 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 35 ms on localhost (2/2)
15/03/04 22:38:13 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
15/03/04 22:38:13 INFO DAGScheduler: Stage 6 (collect at <stdin>:1) finished in 0.037 s
15/03/04 22:38:13 INFO DAGScheduler: Job 5 finished: collect at <stdin>:1, took 0.123883 s
[((u'fox', u'is'), 3), ((u'is', u'red'), 1), ((u'is', u'here'), 1), ((u'crazy', u'fox'), 1), ((u'is', u'crazy'), 1), ((u'jumped', u'high'), 1), ((u'fox', u'jumped'), 1)]
>>> frequency.saveAsTextFile("output")
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 7
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_7
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_7 of size 4696 dropped from memory (free 278036816)
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_7_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_7_piece0 of size 3402 dropped from memory (free 278040218)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:63371 in memory (size: 3.3 KB, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 7
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 6
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_6_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_6_piece0 of size 6251 dropped from memory (free 278046469)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:63371 in memory (size: 6.1 KB, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_6
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_6 of size 8208 dropped from memory (free 278054677)
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 6
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 5
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_5_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_5_piece0 of size 4006 dropped from memory (free 278058683)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:63371 in memory (size: 3.9 KB, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_5_piece0
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_5
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_5 of size 5232 dropped from memory (free 278063915)
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 5
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 4
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_4
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_4 of size 5232 dropped from memory (free 278069147)
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_4_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_4_piece0 of size 4006 dropped from memory (free 278073153)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:63371 in memory (size: 3.9 KB, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 4
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 3
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_3_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_3_piece0 of size 3823 dropped from memory (free 278076976)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:63371 in memory (size: 3.7 KB, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_3
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_3 of size 5056 dropped from memory (free 278082032)
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 3
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 2
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_2
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_2 of size 4456 dropped from memory (free 278086488)
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_2_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_2_piece0 of size 3316 dropped from memory (free 278089804)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:63371 in memory (size: 3.2 KB, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 2
15/03/04 22:38:43 INFO BlockManager: Removing broadcast 1
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_1_piece0
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_1_piece0 of size 1871 dropped from memory (free 278091675)
15/03/04 22:38:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:63371 in memory (size: 1871.0 B, free: 265.4 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/03/04 22:38:43 INFO BlockManager: Removing block broadcast_1
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_1 of size 2528 dropped from memory (free 278094203)
15/03/04 22:38:43 INFO ContextCleaner: Cleaned broadcast 1
15/03/04 22:38:43 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
15/03/04 22:38:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 157 bytes
15/03/04 22:38:43 INFO DAGScheduler: Got job 6 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 2 output partitions (allowLocal=false)
15/03/04 22:38:43 INFO DAGScheduler: Final stage: Stage 8(saveAsTextFile at NativeMethodAccessorImpl.java:-2)
15/03/04 22:38:43 INFO DAGScheduler: Parents of final stage: List(Stage 7)
15/03/04 22:38:43 INFO DAGScheduler: Missing parents: List()
15/03/04 22:38:43 INFO DAGScheduler: Submitting Stage 8 (MappedRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/03/04 22:38:43 INFO MemoryStore: ensureFreeSpace(130664) called with curMem=208353, maxMem=278302556
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 127.6 KB, free 265.1 MB)
15/03/04 22:38:43 INFO MemoryStore: ensureFreeSpace(78956) called with curMem=339017, maxMem=278302556
15/03/04 22:38:43 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 77.1 KB, free 265.0 MB)
15/03/04 22:38:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:63371 (size: 77.1 KB, free: 265.3 MB)
15/03/04 22:38:43 INFO BlockManagerMaster: Updated info of block broadcast_8_piece0
15/03/04 22:38:43 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:838
15/03/04 22:38:43 INFO DAGScheduler: Submitting 2 missing tasks from Stage 8 (MappedRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:-2)
15/03/04 22:38:43 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
15/03/04 22:38:43 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 14, localhost, PROCESS_LOCAL, 1056 bytes)
15/03/04 22:38:43 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 15, localhost, PROCESS_LOCAL, 1056 bytes)
15/03/04 22:38:43 INFO Executor: Running task 0.0 in stage 8.0 (TID 14)
15/03/04 22:38:43 INFO Executor: Running task 1.0 in stage 8.0 (TID 15)
15/03/04 22:38:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/03/04 22:38:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/03/04 22:38:43 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/03/04 22:38:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/03/04 22:38:43 INFO PythonRDD: Times: total = 1, boot = -29797, init = 29798, finish = 0
15/03/04 22:38:43 INFO PythonRDD: Times: total = 2, boot = -29796, init = 29798, finish = 0
15/03/04 22:38:43 INFO FileOutputCommitter: Saved output of task 'attempt_201503042238_0008_m_000001_15' to file:/Users/mparsian/spark-1.2.1/bin/output/_temporary/0/task_201503042238_0008_m_000001
15/03/04 22:38:43 INFO FileOutputCommitter: Saved output of task 'attempt_201503042238_0008_m_000000_14' to file:/Users/mparsian/spark-1.2.1/bin/output/_temporary/0/task_201503042238_0008_m_000000
15/03/04 22:38:43 INFO SparkHadoopWriter: attempt_201503042238_0008_m_000001_15: Committed
15/03/04 22:38:43 INFO SparkHadoopWriter: attempt_201503042238_0008_m_000000_14: Committed
15/03/04 22:38:43 INFO Executor: Finished task 1.0 in stage 8.0 (TID 15). 1801 bytes result sent to driver
15/03/04 22:38:43 INFO Executor: Finished task 0.0 in stage 8.0 (TID 14). 1801 bytes result sent to driver
15/03/04 22:38:43 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 15) in 128 ms on localhost (1/2)
15/03/04 22:38:43 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 14) in 129 ms on localhost (2/2)
15/03/04 22:38:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
15/03/04 22:38:43 INFO DAGScheduler: Stage 8 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) finished in 0.130 s
15/03/04 22:38:43 INFO DAGScheduler: Job 6 finished: saveAsTextFile at NativeMethodAccessorImpl.java:-2, took 0.178077 s
>>> exiit()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'exiit' is not defined
>>> ^D
15/03/04 22:38:52 INFO SparkUI: Stopped Spark web UI at http://192.168.1.4:4040
15/03/04 22:38:52 INFO DAGScheduler: Stopping DAGScheduler
15/03/04 22:38:53 INFO MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
15/03/04 22:38:53 INFO MemoryStore: MemoryStore cleared
15/03/04 22:38:53 INFO BlockManager: BlockManager stopped
15/03/04 22:38:53 INFO BlockManagerMaster: BlockManagerMaster stopped
15/03/04 22:38:53 INFO SparkContext: Successfully stopped SparkContext
15/03/04 22:38:53 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/03/04 22:38:53 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/03/04 22:38:53 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
mparsian@Mahmouds-MacBook:~/spark-1.2.1/bin# cat output/part*
((u'fox', u'is'), 3)
((u'is', u'red'), 1)
((u'is', u'here'), 1)
((u'crazy', u'fox'), 1)
((u'is', u'crazy'), 1)
((u'jumped', u'high'), 1)
((u'fox', u'jumped'), 1)
mparsian@Mahmouds-MacBook:~/spark-1.2.1/bin#
